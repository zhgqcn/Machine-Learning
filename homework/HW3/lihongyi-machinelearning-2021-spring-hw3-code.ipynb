{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import necessary packages.\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torchvision import datasets, models, transforms\nfrom PIL import Image\n# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\nfrom torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\nfrom torchvision.datasets import DatasetFolder\n\n# This is for the progress bar.\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-05-24T03:52:22.209558Z","iopub.execute_input":"2021-05-24T03:52:22.210022Z","iopub.status.idle":"2021-05-24T03:52:22.218508Z","shell.execute_reply.started":"2021-05-24T03:52:22.209978Z","shell.execute_reply":"2021-05-24T03:52:22.216702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# It is important to do data augmentation in training.\n# However, not every augmentation is useful.\n# Please think about what kind of augmentation is helpful for food recognition.\ntrain_tfm = transforms.Compose([\n    # Resize the image into a fixed shape (height = width = 128)\n    transforms.Resize((128, 128)),\n    # You may add some transforms here.\n    transforms.RandomHorizontalFlip(0.5),                    # 实现水平随机翻转\n    #transforms.ColorJitter(brightness=0.5, contrast=0.5, hue=0.5),  # 色彩抖动\n    # ToTensor() should be the last one of the transforms.\n    transforms.ToTensor(),\n])\n\n# We don't need augmentations in testing and validation.\n# All we need here is to resize the PIL image and transform it into Tensor.\ntest_tfm = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.ToTensor(),\n])","metadata":{"execution":{"iopub.status.busy":"2021-05-24T03:52:23.325399Z","iopub.execute_input":"2021-05-24T03:52:23.325831Z","iopub.status.idle":"2021-05-24T03:52:23.333036Z","shell.execute_reply.started":"2021-05-24T03:52:23.325799Z","shell.execute_reply":"2021-05-24T03:52:23.331432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Batch size for training, validation, and testing.\n# A greater batch size usually gives a more stable gradient.\n# But the GPU memory is limited, so please adjust it carefully.\nbatch_size = 64\n\n# Construct datasets.\n# The argument \"loader\" tells how torchvision reads the data.\ntrain_set = DatasetFolder(\"../input/lihongyimachinelearning2021spring-hw3/food-11/training/labeled\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=train_tfm)\nvalid_set = DatasetFolder(\"../input/lihongyimachinelearning2021spring-hw3/food-11/validation\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=test_tfm)\nunlabeled_set = DatasetFolder(\"../input/lihongyimachinelearning2021spring-hw3/food-11/training/unlabeled\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=train_tfm)\ntest_set = DatasetFolder(\"../input/lihongyimachinelearning2021spring-hw3/food-11/testing\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=test_tfm)\n\n# Construct data loaders.\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\nvalid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\ntest_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T03:52:23.552654Z","iopub.execute_input":"2021-05-24T03:52:23.553048Z","iopub.status.idle":"2021-05-24T03:52:27.742453Z","shell.execute_reply.started":"2021-05-24T03:52:23.553018Z","shell.execute_reply":"2021-05-24T03:52:27.741191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 迁移学习\nresnet18 = models.resnet18(pretrained=True)\n\nfor param in resnet18.parameters():\n    param.pretrained = False\n\nfc_inputs = resnet18.fc.in_features\nresnet18.fc = nn.Sequential(\n    nn.Linear(fc_inputs, 256),\n    nn.ReLU(),\n    nn.Dropout(0.4),\n    nn.Linear(256, 11)\n    # nn.LogSoftmax(dim=1)\n)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T03:52:27.744516Z","iopub.execute_input":"2021-05-24T03:52:27.745009Z","iopub.status.idle":"2021-05-24T03:52:28.201946Z","shell.execute_reply.started":"2021-05-24T03:52:27.74496Z","shell.execute_reply":"2021-05-24T03:52:28.200797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://github.com/ycheng627/EEML/blob/30ceeb4fa03818149688ed7ac68d92a56e83fd97/hw3/pseudolabel.py#L10\nclass PseudoDataset(Dataset):\n    r\"\"\"\n    Subset of a dataset at specified indices.\n    Arguments:\n        dataset (Dataset): The whole Dataset\n        indices (sequence): Indices in the whole set selected for subset\n        labels(sequence) : targets as required for the indices. will be the same length as indices\n    \"\"\"\n    def __init__(self, dataset, labels, indices, device):\n        self.dataset = Subset(dataset, indices)\n        self.targets = labels\n    def __getitem__(self, idx):\n        image = self.dataset[idx]\n        target = self.targets[idx]\n        return (image, target)\n\n    def __len__(self):\n        return len(self.targets)\n\n\ndef get_pseudo_labels(dataset, model, threshold=0.75):\n    # This functions generates pseudo-labels of a dataset using given model.\n    # It returns an instance of DatasetFolder containing images whose prediction confidences exceed a given threshold.\n    # You are NOT allowed to use any models trained on external data for pseudo-labeling.\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    \n    input_image = []   # 训练数据\n    fake_target = []   # 对应标签\n\n    # Construct a data loader.\n    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n\n    # Make sure the model is in eval mode.\n    model.eval()\n    # Define softmax function.\n    softmax = nn.Softmax(dim=-1)\n\n    # Iterate over the dataset by batches.\n    for batch in tqdm(data_loader):\n        img, _ = batch\n        \n        # Forward the data\n        # Using torch.no_grad() accelerates the forward process.\n        with torch.no_grad():\n            logits = model(img.to(device))\n\n        # Obtain the probability distributions by applying softmax on logits.\n        probs = softmax(logits)\n        \n        # ---------- TODO ----------\n        # Filter the data and construct a new dataset.\n        index = 0          # 索引 batch\n        for p in probs:\n                if torch.max(p) > threshold:\n                    input_image.append(img[index])\n                    fake_target.append(torch.argmax(p).cpu().item())\n                    index += 1\n\n    # # Turn off the eval mode.\n    model.train()\n    dataset = [*zip(input_image, fake_target)]\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2021-05-24T03:52:28.204549Z","iopub.execute_input":"2021-05-24T03:52:28.204998Z","iopub.status.idle":"2021-05-24T03:52:28.220082Z","shell.execute_reply.started":"2021-05-24T03:52:28.204954Z","shell.execute_reply":"2021-05-24T03:52:28.216914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fix random seed\ndef same_seeds(seed):\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)  \n    np.random.seed(seed)  \n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\nsame_seeds(1)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T03:52:28.222388Z","iopub.execute_input":"2021-05-24T03:52:28.223263Z","iopub.status.idle":"2021-05-24T03:52:28.285331Z","shell.execute_reply.started":"2021-05-24T03:52:28.223166Z","shell.execute_reply":"2021-05-24T03:52:28.284196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# \"cuda\" only when GPUs are available.\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Initialize a model, and put it on the device specified.\nmodel = resnet18.to(device)\nmodel.load_state_dict(torch.load('./a-resnet18_4_0.7582386136054993.pth'))\nmodel.device = device\n\n# For the classification task, we use cross-entropy as the measurement of performance.\ncriterion = nn.CrossEntropyLoss()\n\n# Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T03:52:57.184796Z","iopub.execute_input":"2021-05-24T03:52:57.185287Z","iopub.status.idle":"2021-05-24T03:53:02.226114Z","shell.execute_reply.started":"2021-05-24T03:52:57.185201Z","shell.execute_reply":"2021-05-24T03:53:02.224853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The number of training epochs.\nn_epochs = 100\n\n# Whether to do semi-supervised learning.\ndo_semi = True\n\n# save best model\nbest_acc = 0.75\n\nfor epoch in range(n_epochs):\n    # ---------- TODO ----------\n    # In each epoch, relabel the unlabeled dataset for semi-supervised learning.\n    # Then you can combine the labeled dataset and pseudo-labeled dataset for the training.\n    if do_semi:\n        # Obtain pseudo-labels for unlabeled data using trained model.\n        pseudo_set = get_pseudo_labels(unlabeled_set, model)\n\n        # Construct a new dataset and a data loader for training.\n        # This is used in semi-supervised learning only.\n        concat_dataset = ConcatDataset([train_set, pseudo_set])\n        train_loader = DataLoader(concat_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n\n    # ---------- Training ----------\n    # Make sure the model is in train mode before training.\n    model.train()\n\n    # These are used to record information in training.\n    train_loss = []\n    train_accs = []\n\n    # Iterate the training set by batches.\n    for batch in tqdm(train_loader):\n\n        # A batch consists of image data and corresponding labels.\n        imgs, labels = batch\n\n        # Forward the data. (Make sure data and model are on the same device.)\n        logits = model(imgs.to(device))\n\n        # Calculate the cross-entropy loss.\n        # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n        loss = criterion(logits, labels.to(device))\n\n        # Gradients stored in the parameters in the previous step should be cleared out first.\n        optimizer.zero_grad()\n\n        # Compute the gradients for parameters.\n        loss.backward()\n\n        # Clip the gradient norms for stable training.\n        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n\n        # Update the parameters with computed gradients.\n        optimizer.step()\n\n        # Compute the accuracy for current batch.\n        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n\n        # Record the loss and accuracy.\n        train_loss.append(loss.item())\n        train_accs.append(acc)\n\n    # The average loss and accuracy of the training set is the average of the recorded values.\n    train_loss = sum(train_loss) / len(train_loss)\n    train_acc = sum(train_accs) / len(train_accs)\n\n    # Print the information.\n    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n\n    # ---------- Validation ----------\n    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n    model.eval()\n\n    # These are used to record information in validation.\n    valid_loss = []\n    valid_accs = []\n\n    # Iterate the validation set by batches.\n    for batch in tqdm(valid_loader):\n\n        # A batch consists of image data and corresponding labels.\n        imgs, labels = batch\n\n        # We don't need gradient in validation.\n        # Using torch.no_grad() accelerates the forward process.\n        with torch.no_grad():\n            logits = model(imgs.to(device))\n\n        # We can still compute the loss (but not the gradient).\n        loss = criterion(logits, labels.to(device))\n\n        # Compute the accuracy for current batch.\n        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n\n        # Record the loss and accuracy.\n        valid_loss.append(loss.item())\n        valid_accs.append(acc)\n\n    # The average loss and accuracy for entire validation set is the average of the recorded values.\n    valid_loss = sum(valid_loss) / len(valid_loss)\n    valid_acc = sum(valid_accs) / len(valid_accs)\n\n    # if the model improves, save a checkpoint at this epoch\n    if valid_acc > best_acc:\n        best_acc = valid_acc\n        torch.save(model.state_dict(), './b-resnet18_' + str(epoch) + '_' + str(valid_acc.cpu().item()) + '.pth')\n        print('save best model now.')\n\n    # Print the information.\n    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")","metadata":{"execution":{"iopub.status.busy":"2021-05-24T03:53:36.355886Z","iopub.execute_input":"2021-05-24T03:53:36.356359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make sure the model is in eval mode.\n# Some modules like Dropout or BatchNorm affect if the model is in training mode.\n\nmodel.load_state_dict(torch.load('./a-resnet18_9_0.7704545855522156.pth'))\nmodel.eval()\n\n# Initialize a list to store the predictions.\npredictions = []\n\n# Iterate the testing set by batches.\nfor batch in tqdm(test_loader):\n    # A batch consists of image data and corresponding labels.\n    # But here the variable \"labels\" is useless since we do not have the ground-truth.\n    # If printing out the labels, you will find that it is always 0.\n    # This is because the wrapper (DatasetFolder) returns images and labels for each batch,\n    # so we have to create fake labels to make it work normally.\n    imgs, labels = batch\n\n    # We don't need gradient in testing, and we don't even have labels to compute loss.\n    # Using torch.no_grad() accelerates the forward process.\n    with torch.no_grad():\n        logits = model(imgs.to(device))\n\n    # Take the class with greatest logit as prediction and record it.\n    predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())","metadata":{"execution":{"iopub.status.busy":"2021-05-24T03:07:52.981467Z","iopub.execute_input":"2021-05-24T03:07:52.981884Z","iopub.status.idle":"2021-05-24T03:08:28.702057Z","shell.execute_reply.started":"2021-05-24T03:07:52.981838Z","shell.execute_reply":"2021-05-24T03:08:28.701169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save predictions into the file.\nwith open(\"predict.csv\", \"w\") as f:\n\n    # The first row must be \"Id, Category\"\n    f.write(\"Id,Category\\n\")\n\n    # For the rest of the rows, each image id corresponds to a predicted class.\n    for i, pred in  enumerate(predictions):\n        f.write(f\"{i},{pred}\\n\")\n    print('saved!') ","metadata":{"execution":{"iopub.status.busy":"2021-05-24T03:09:11.267168Z","iopub.execute_input":"2021-05-24T03:09:11.267496Z","iopub.status.idle":"2021-05-24T03:09:11.276488Z","shell.execute_reply.started":"2021-05-24T03:09:11.267466Z","shell.execute_reply":"2021-05-24T03:09:11.275434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}